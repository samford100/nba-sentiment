{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_posts(subreddit):\n",
    "    from bs4 import BeautifulSoup, SoupStrainer, Comment\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    headers = {\n",
    "        \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9\",\n",
    "    }\n",
    "\n",
    "    result = requests.get('https://www.reddit.com' + subreddit, headers=headers)\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "    content = soup.findAll(class_=\"title\")\n",
    "\n",
    "    titles = content[2:-4:2] # need to cut out first two and last 4 and repeating titles\n",
    "\n",
    "    sentences = [sen.text for sen in titles]\n",
    "    paragraph = ' '.join(w.strip() for w in [sen.text for sen in titles])\n",
    "    return paragraph, sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# nltk.download('vader_lexicon')\n",
    "# nltk.download('punkt')\n",
    "def analyze_paragraph(paragraph):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    ss = sid.polarity_scores(paragraph)\n",
    "    return ss['pos'], ss['neu'], ss['neg'], ss['compound']\n",
    "    \n",
    "def analyze_sentences(sentences):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    pos, neu, neg, com = 0,0,0,0\n",
    "    for sentence in sentences:\n",
    "        ss = sid.polarity_scores(sentence)\n",
    "        pos += ss['pos']\n",
    "        neu += ss['neu']\n",
    "        neg += ss['neg']\n",
    "        com += ss['compound']\n",
    "        \n",
    "    return pos, neu, neg, com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_days_teams():\n",
    "    # get games of the day\n",
    "    from bs4 import BeautifulSoup, SoupStrainer, Comment\n",
    "    import requests\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "\n",
    "    headers = {\n",
    "        \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9\",\n",
    "    }\n",
    "\n",
    "    now = datetime.datetime.now()\n",
    "\n",
    "    url = \"https://www.basketball-reference.com/boxscores/?month={0}&day={1}&year={2}\".format(now.month, now.day-1, now.year)\n",
    "\n",
    "    result = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(result.content, 'html.parser')\n",
    "    content = soup.findAll(class_=\"teams\")\n",
    "\n",
    "    winners = []\n",
    "    losers = []\n",
    "    for teams in content:\n",
    "        # find winner\n",
    "        winner = teams.find(class_=\"winner\")\n",
    "        for td in winner.find('td'):\n",
    "            winners.append(td.text)\n",
    "        loser = teams.find(class_=\"loser\")\n",
    "        for td in loser.find('td'):\n",
    "            losers.append(td.text)\n",
    "\n",
    "    return winners, losers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subreddits = {\n",
    "    'LA Lakers': '/r/lakers',\n",
    "    'Golden State' : '/r/warriors',\n",
    "    'Chicago' : '/r/chicagobulls',\n",
    "    'Toronto' : '/r/torontoraptors',\n",
    "    'Boston' : '/r/bostonceltics',\n",
    "    'Cleveland' : '/r/clevelandcavs',\n",
    "    'New York' : '/r/nyknicks',\n",
    "    'San Antonio' : '/r/nbaspurs',\n",
    "    'Miami' : '/r/heat',\n",
    "    'Houston' : '/r/rockets',\n",
    "    'Philadelphia' : '/r/sixers',\n",
    "    'Portland' : '/r/ripcity',\n",
    "    'Oklahoma' : '/r/thunder',\n",
    "    'Minnesota' : '/r/timberwolves',\n",
    "    'Dallas' : '/r/mavericks',\n",
    "    'Atlanta' : '/r/atlantahawks',\n",
    "    'LA Clippers' : '/r/laclippers',\n",
    "    'Detroit' : '/r/detroitpistons',\n",
    "    'Washington' : '/r/washingtonwizards',\n",
    "    'Charlotte' : '/r/charlottehornets',\n",
    "    'Sacramento' : '/r/kings',\n",
    "    'Milwaukee' : '/r/mkebucks',\n",
    "    'Phoenix' : '/r/suns',\n",
    "    'Indiana' : '/r/pacers',\n",
    "    'Orlando' : '/r/orlandomagic',\n",
    "    'Denver' : '/r/denvernuggets',\n",
    "    'Utah' : '/r/utahjazz',\n",
    "    'Brooklyn' : '/r/gonets',\n",
    "    'Memphis' : '/r/memphisgrizzlies',\n",
    "    'New Orleans' : '/r/nolapelicans'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def compute_all():\n",
    "    winners, losers = get_days_teams()\n",
    "    winner_data = compute_winners(winners)\n",
    "    loser_data = compute_losers(losers)\n",
    "    data = winner_data + loser_data\n",
    "    return data\n",
    "    \n",
    "def compute_winners(winners):\n",
    "    data = []\n",
    "    for team in winners:\n",
    "        paragraph, sentences = get_posts(subreddits[team])\n",
    "        sen_pos, sen_neu, sen_neg, sen_com = analyze_sentences(sentences)\n",
    "        par_pos, par_neu, par_neg, par_com = analyze_paragraph(paragraph)\n",
    "        data.append([team, sen_pos, sen_neu, sen_neg, sen_com, par_pos, par_neu, par_neg, par_com, True])\n",
    "    return data\n",
    "\n",
    "def compute_losers(losers):       \n",
    "    data = []\n",
    "    for team in losers:\n",
    "        paragraph, sentences = get_posts(subreddits[team])\n",
    "        sen_pos, sen_neu, sen_neg, sen_com = analyze_sentences(sentences)\n",
    "        par_pos, par_neu, par_neg, par_com = analyze_paragraph(paragraph)\n",
    "        data.append([team, sen_pos, sen_neu, sen_neg, sen_com, par_pos, par_neu, par_neg, par_com, False])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    team  sen_pos  sen_neu  sen_neg  sen_com  par_pos  par_neu  par_neg  par_com    won\n",
      "date                                                                                                                   \n",
      "2018-01-07 15:30:53.709398        Boston      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   True\n",
      "2018-01-07 15:30:53.709398       Detroit      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   True\n",
      "2018-01-07 15:30:53.709398       Indiana      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   True\n",
      "2018-01-07 15:30:53.709398  Golden State      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   True\n",
      "2018-01-07 15:30:53.709398     Minnesota      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   True\n",
      "2018-01-07 15:30:53.709398     Cleveland      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   True\n",
      "2018-01-07 15:30:53.709398    Sacramento      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   True\n",
      "2018-01-07 15:30:53.709398     Milwaukee      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   True\n",
      "2018-01-07 15:30:53.709398      Brooklyn      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  False\n",
      "2018-01-07 15:30:53.709398       Houston      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  False\n",
      "2018-01-07 15:30:53.709398       Chicago      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  False\n",
      "2018-01-07 15:30:53.709398   LA Clippers      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  False\n",
      "2018-01-07 15:30:53.709398   New Orleans      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  False\n",
      "2018-01-07 15:30:53.709398       Orlando      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  False\n",
      "2018-01-07 15:30:53.709398        Denver      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  False\n",
      "2018-01-07 15:30:53.709398    Washington      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0  False\n"
     ]
    }
   ],
   "source": [
    "# store results\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1200)\n",
    "\n",
    "data = compute_all()\n",
    "df = pd.DataFrame(data, columns=('team', 'sen_pos', 'sen_neu', 'sen_neg', 'sen_com', 'par_pos', 'par_neu', 'par_neg', 'par_com', 'won'))\n",
    "df['date'] = pd.to_datetime(datetime.datetime.now())\n",
    "df.index = df['date']\n",
    "del df['date']\n",
    "print(df.head(n=50))\n",
    "with open('nba_sentiment.csv', 'a') as f:\n",
    "    df.to_csv(f, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
